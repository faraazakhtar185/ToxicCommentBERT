{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ea8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34642e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_labels = pd.read_csv('test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbbde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['id'])\n",
    "test = test.drop(columns=['id'])\n",
    "#train['comment_text'] = train['comment_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cf23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to remove punctuation using regular expressions\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "train['comment_text'] = train['comment_text'].apply(remove_punctuation)\n",
    "test['comment_text'] = test['comment_text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03675510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove special characters using regular expressions\n",
    "def remove_special_characters(text):\n",
    "    # Define a regular expression pattern to match special characters\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'  # This pattern matches any character that is not a letter, digit, or whitespace\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "train['comment_text'] = train['comment_text'].apply(remove_special_characters)\n",
    "test['comment_text'] = test['comment_text'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781800c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm theres no actual article for p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\\nAnd  I really dont think you understand  I c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic   \n",
       "0       Explanation\\nWhy the edits made under my usern...      0  \\\n",
       "1       Daww He matches this background colour Im seem...      0   \n",
       "2       Hey man Im really not trying to edit war Its j...      0   \n",
       "3       \\nMore\\nI cant make any real suggestions on im...      0   \n",
       "4       You sir are my hero Any chance you remember wh...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  And for the second time of asking when your vi...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm theres no actual article for p...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \\nAnd  I really dont think you understand  I c...      0   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0                  0        0       0       0              0  \n",
       "1                  0        0       0       0              0  \n",
       "2                  0        0       0       0              0  \n",
       "3                  0        0       0       0              0  \n",
       "4                  0        0       0       0              0  \n",
       "...              ...      ...     ...     ...            ...  \n",
       "159566             0        0       0       0              0  \n",
       "159567             0        0       0       0              0  \n",
       "159568             0        0       0       0              0  \n",
       "159569             0        0       0       0              0  \n",
       "159570             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70781f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Tokenize Comments - using max token length along with attention mask\n",
    "tokenized_data = train['comment_text'].apply(lambda x: tokenizer(x, padding = 'max_length', max_length = 512, truncation = True, return_tensors='pt'))\n",
    "tokenized_eval_data = test['comment_text'].apply(lambda x: tokenizer(x, padding = 'max_length', max_length = 512, truncation = True, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49328dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels\n",
    "labels = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "eval_labels = test_labels[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "# Convert to a PyTorch tensor\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "eval_labels_tensor = torch.tensor(eval_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f44864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df69f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the encodings\n",
    "encodings = {\n",
    "    'input_ids': torch.cat([x['input_ids'] for x in tokenized_data]),\n",
    "    'attention_mask': torch.cat([x['attention_mask'] for x in tokenized_data])\n",
    "}\n",
    "# Create the dataset\n",
    "dataset = ToxicCommentsDataset(encodings, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ecdce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the encodings\n",
    "eval_encodings = {\n",
    "    'input_ids': torch.cat([x['input_ids'] for x in tokenized_eval_data]),\n",
    "    'attention_mask': torch.cat([x['attention_mask'] for x in tokenized_eval_data])\n",
    "}\n",
    "# Create the dataset\n",
    "eval_dataset = ToxicCommentsDataset(eval_encodings, eval_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2f54895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3335101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom model for multi-label classification\n",
    "class BertForMultiLabelClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13fbcf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f8be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForMultiLabelClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/1p/mcbdw1kn2zdd70vwy8vxx8680000gn/T/ipykernel_59593/1208786421.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='59841' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/59841 06:19 < 6311:02:31, 0.00 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of labels\n",
    "num_labels = 6\n",
    "\n",
    "# Create a configuration object with the appropriate number of labels\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "# Initialize the model with the configuration\n",
    "model = BertForMultiLabelClassification.from_pretrained('bert-base-uncased', config=config)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Create the Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
